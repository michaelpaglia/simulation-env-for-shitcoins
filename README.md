# ğŸ° Shitcoin Social Simulation Environment

Simulate how your token will perform on Crypto Twitter **before** you launch. Test narratives, memes, and timing in a sandbox with AI-powered personas.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Token Concept  â”‚â”€â”€â”€â–¶â”‚  CT Simulation   â”‚â”€â”€â”€â–¶â”‚  LLM Feedback   â”‚
â”‚  name/ticker/   â”‚    â”‚  personas react  â”‚    â”‚  iterate/refine â”‚
â”‚  narrative      â”‚    â”‚  viral spread    â”‚    â”‚  before launch  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Table of Contents

- [Concept](#-concept)
- [Quick Start](#-quick-start)
- [CLI Commands](#-cli-commands)
- [Token Presets](#-token-presets)
- [LLM Feedback Loop](#-llm-feedback-loop)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [API Endpoints](#-api-endpoints)
- [Agent Personas](#-agent-personas)
- [Metrics](#-metrics)
- [Roadmap](#-roadmap)

---

## ğŸ’¡ Concept

Instead of launching blind and hoping for virality, run your token through a simulated CT environment:

| Feature | Description |
|---------|-------------|
| ğŸ¤– **AI Agents** | Degens, skeptics, whales, influencers, KOLs react to your token |
| ğŸ“ˆ **Viral Modeling** | See how your meme spreads (or doesn't) |
| ğŸ’¬ **Sentiment Tracking** | Measure hype, FUD, and engagement over time |
| ğŸ”„ **LLM Feedback Loop** | AI evaluates your concept and suggests improvements |
| ğŸ’¾ **Save & Export** | Persist simulations as JSON/CSV for analysis |
| âš¡ **Iterate Fast** | Test 10 variations in an hour instead of burning money |

---

## ğŸš€ Quick Start

### Option 1: Web UI

```bash
pip install -r requirements.txt
python run_api.py

# In another terminal
cd web && npm install && npm run dev
```
â†’ Open http://localhost:3000

### Option 2: CLI

```bash
pip install -r requirements.txt
export ANTHROPIC_API_KEY=your_key_here  # optional, for AI responses

# Quick simulation with preset
python -m src.cli quick --preset doge

# Full simulation
python -m src.cli simulate \
  --name "PEPE2" \
  --ticker "PEPE2" \
  --narrative "The sequel nobody asked for"

# Compare tickers
python -m src.cli compare DOGE SHIB PEPE --narrative "classic meme"
```

---

## ğŸ–¥ï¸ CLI Commands

| Command | Description | Example |
|---------|-------------|---------|
| `simulate` | Full simulation with all options | `--name X --ticker X --narrative "..."` |
| `quick` | Fast sim with minimal config | `quick WOJAK "sad frog"` |
| `quick --preset` | Use a preset template | `quick --preset ai` |
| `compare` | Compare multiple tickers | `compare DOGE SHIB PEPE` |
| `presets` | List available presets | `presets` |

---

## ğŸ¨ Token Presets

Pre-configured templates for common archetypes:

| Preset | Ticker | Style | Description |
|--------|--------|-------|-------------|
| `doge` | $DOGE | ğŸ• Cute | Classic dog coin, wholesome community vibes |
| `ai` | $AGENT | ğŸ¤– Topical | AI agent narrative, riding the hype wave |
| `pepe` | $PEPE | ğŸ¸ Nostalgic | Iconic frog, classic meme culture |
| `cat` | $CAT | ğŸ± Cute | Cat supremacy, anti-dog narrative |
| `edgy` | $EDGE | ğŸ”ª Edgy | Dark humor for degen audiences |
| `meta` | $META | ğŸª Absurd | Self-aware ironic commentary |

```bash
# Use preset with custom ticker
python -m src.cli quick --preset pepe KEKE
```

---

## ğŸ” LLM Feedback Loop

The feedback system evaluates concepts using synthetic simulation + LLM analysis:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Concept    â”‚â”€â”€â”€â”€â–¶â”‚   Simulate    â”‚â”€â”€â”€â”€â–¶â”‚  LLM Eval    â”‚â”€â”€â”€â”€â–¶â”‚   Iterate    â”‚
â”‚              â”‚     â”‚               â”‚     â”‚              â”‚     â”‚              â”‚
â”‚ name/ticker  â”‚     â”‚ CT personas   â”‚     â”‚ "weak hook"  â”‚     â”‚ refine until â”‚
â”‚ narrative    â”‚     â”‚ react & post  â”‚     â”‚ "FUD risk"   â”‚     â”‚ viable       â”‚
â”‚ hook         â”‚     â”‚ over N hours  â”‚     â”‚ "try X"      â”‚     â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Module | Purpose |
|--------|---------|
| `SimulationObserver` | Extracts state/metrics from running simulation |
| `LLMAnalyzer` | Sends context to Claude, parses structured feedback |
| `AdjustmentEngine` | Applies parameter changes with constraints |
| `FeedbackLoop` | Orchestrates observe â†’ analyze â†’ adjust cycle |
| `TokenEvaluator` | Quick concept evaluation without full sim |
| `CTConceptEvaluator` | Full CT simulation + LLM checkpoints |

### Examples

```bash
# Quick concept evaluation (no full sim)
python -m llm_feedback.examples.evaluate_concept

# Full CT simulation with LLM feedback
python -m llm_feedback.examples.run_ct_evaluation

# Synthetic market demo (works without API key with --mock)
python -m llm_feedback.examples.synthetic_market --mock
```

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/           # ğŸ¤– AI persona definitions
â”‚   â”‚   â””â”€â”€ personas.py   #    Degen, Skeptic, Whale, Influencer, etc.
â”‚   â”œâ”€â”€ analysis/         # ğŸ“Š Post-simulation analysis
â”‚   â”‚   â””â”€â”€ impact.py     #    Persona impact metrics
â”‚   â”œâ”€â”€ api/              # ğŸŒ FastAPI backend
â”‚   â”‚   â””â”€â”€ main.py       #    REST endpoints
â”‚   â”œâ”€â”€ models/           # ğŸ“¦ Data models
â”‚   â”‚   â””â”€â”€ token.py      #    Token, SimulationResult (Pydantic)
â”‚   â”œâ”€â”€ presets/          # ğŸ¨ Token templates
â”‚   â”‚   â””â”€â”€ templates.py  #    doge, ai, pepe, cat, edgy, meta
â”‚   â”œâ”€â”€ simulation/       # âš™ï¸ Core engine
â”‚   â”‚   â””â”€â”€ engine.py     #    SimulationEngine, Tweet generation
â”‚   â”œâ”€â”€ utils/            # ğŸ”§ Utilities
â”‚   â”‚   â”œâ”€â”€ persistence.py#    Save/load simulations (JSON/CSV)
â”‚   â”‚   â””â”€â”€ twitter.py    #    Twitter API integration
â”‚   â””â”€â”€ cli.py            # ğŸ’» Command-line interface
â”‚
â”œâ”€â”€ llm_feedback/         # ğŸ” LLM feedback loop system
â”‚   â”œâ”€â”€ observer.py       #    State extraction
â”‚   â”œâ”€â”€ analyzer.py       #    LLM analysis
â”‚   â”œâ”€â”€ adjustments.py    #    Parameter adjustment
â”‚   â”œâ”€â”€ feedback_loop.py  #    Orchestration
â”‚   â”œâ”€â”€ token_evaluator.py#    Concept evaluation
â”‚   â”œâ”€â”€ ct_integration.py #    CT simulation integration
â”‚   â””â”€â”€ examples/         #    Runnable demos
â”‚
â”œâ”€â”€ web/                  # ğŸ–¼ï¸ Next.js frontend
â”œâ”€â”€ tests/                # ğŸ§ª Test suite (92 tests)
â”œâ”€â”€ run_api.py            # API server entrypoint
â””â”€â”€ requirements.txt
```

---

## âš™ï¸ Configuration

Copy `.env.example` to `.env`:

```bash
# Required for AI-powered responses
ANTHROPIC_API_KEY=your_anthropic_key

# Optional: Twitter data calibration
TWITTER_BEARER_TOKEN=your_bearer_token
TWITTER_CONSUMER_KEY=your_consumer_key
TWITTER_ACCESS_TOKEN=your_access_token
```

---

## ğŸŒ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/simulate` | POST | Run a full simulation |
| `/market-sentiment` | GET | Current CT market sentiment |
| `/twitter-prior` | GET | Twitter data for a token |
| `/personas` | GET | List available personas |

---

## ğŸ­ Agent Personas

### Generic Archetypes

| Persona | Behavior | Sentiment |
|---------|----------|-----------|
| ğŸ² **Degen** | Apes first, asks questions never | Bullish |
| ğŸ” **Skeptic** | Calls everything a rug | Bearish |
| ğŸ‹ **Whale** | Few words, big impact | Neutral |
| ğŸ“¢ **Influencer** | Chases clout, shills momentum | Variable |
| ğŸ‘¤ **Normie** | Follows the crowd | Lagging |

### Real KOLs (from Kolscan)

- ansem (@blknoiz06)
- LilMoonLambo
- Groovy (@0xGroovy)
- Insyder (@insydercrypto)
- Monarch (@MonarchBTC)
- ShockedJS
- Levis (@LevisNFT)
- Hail (@ignHail)

---

## ğŸ“Š Metrics

After simulation:

| Metric | Description |
|--------|-------------|
| **Viral Coefficient** | Engagement multiplier (1.0 = baseline) |
| **Peak Sentiment** | Maximum hype reached (-1.0 to +1.0) |
| **Sentiment Stability** | How steady the sentiment held |
| **FUD Resistance** | Survival rate against skeptics (0-100%) |
| **Hours to Peak** | Time to maximum engagement |
| **Hours to Death** | Time until interest collapsed (if any) |
| **Predicted Outcome** | `moon` / `cult_classic` / `pump_and_dump` / `slow_bleed` / `rug` |
| **Dominant Narrative** | What CT ended up calling your token |

### Persona Impact Analysis

```bash
# See which personas drove engagement
python -m src.cli impact <simulation_file>
```

Output shows per-persona breakdown:
- Tweet count & average sentiment
- Engagement share (%)
- Hype drivers vs FUD sources

---

## ğŸ—ºï¸ Roadmap

- [x] Core simulation engine
- [x] Basic agent personas
- [x] Real KOL personas
- [x] Web UI for visual feed
- [x] FastAPI backend
- [x] Twitter API integration
- [x] Save/export simulation runs
- [x] Token preset templates
- [x] LLM feedback loop
- [x] Persona impact analysis
- [ ] Historical data calibration
- [ ] Multi-token competition simulation
- [ ] Telegram/Discord simulation

---

## ğŸ“„ License

MIT
